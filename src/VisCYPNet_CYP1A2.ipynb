{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: PyTorch Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os                                 \n",
    "import pandas as pd                      \n",
    "from PIL import Image                     \n",
    "import torch                             \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "from torchvision import transforms        \n",
    "from ImageDataset import CYPImageDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transforms \n",
    "# We resize, center‑crop to 224×224, convert to tensor, and normalize.\n",
    "\n",
    "# Use CLIP normalization\n",
    "CLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
    "CLIP_STD  = (0.26862954, 0.26130258, 0.27577711)\n",
    "\n",
    "no_aug_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),                            # ensure min side=256\n",
    "    transforms.CenterCrop(224),                        # crop to 224×224\n",
    "    transforms.ToTensor(),                             # PIL→FloatTensor, scales to [0,1]\n",
    "    transforms.Normalize(CLIP_MEAN, CLIP_STD)          # Use CLIP normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train batches: 315,  Val batches: 40,  Test batches: 40\n"
     ]
    }
   ],
   "source": [
    "# Instantiate DataLoaders  (for CYP1A2)\n",
    "\n",
    "from ImageDataset import CYPImageDataset\n",
    "\n",
    "# Common loader settings\n",
    "batch_size  = 32\n",
    "num_workers = 4\n",
    "\n",
    "# Training set\n",
    "train_ds = CYPImageDataset(\n",
    "    csv_file=\"../data/processed/1A2_train.csv\",\n",
    "    image_dir=\"../images/1A2/train/clean\",\n",
    "    transform=no_aug_transforms\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,        # shuffle for training\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True      # speeds up host→GPU transfer\n",
    ")\n",
    "\n",
    "# Validation set\n",
    "val_ds = CYPImageDataset(\n",
    "    csv_file=\"../data/processed/1A2_val.csv\",\n",
    "    image_dir=\"../images/1A2/val/clean\",\n",
    "    transform=no_aug_transforms\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,       \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Test set\n",
    "test_ds = CYPImageDataset(\n",
    "    csv_file=\"../data/processed/1A2_test.csv\",\n",
    "    image_dir=\"../images/1A2/test/clean\",\n",
    "    transform=no_aug_transforms\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,      \n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# Quick sanity check\n",
    "print(f\"Train batches: {len(train_loader)},  Val batches: {len(val_loader)},  Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Model Definition & Transfer‑Learning Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. first load the standard CLIP ViT via the clip library (e.g. clip.load(\"ViT‑B/16\")).\n",
    "\n",
    "2. wrap and rename its visual submodule as backbone.\n",
    "\n",
    "3. then load the MoleCLIP checkpoint (the .pth file) and filter for all keys beginning with visual.\n",
    "\n",
    "4. call backbone.load_state_dict(moleclip_state, strict=False), which replaces the vanilla CLIP weights with the MoleCLIP‑fine‑tuned weights.\n",
    "\n",
    "5. Finally, freeze those backbone parameters and add  new CYPHead on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Robust MoleCLIP backbone loading + fine-tune-friendly setup ===\n",
    "import os\n",
    "import torch\n",
    "import clip\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Settings you can tweak\n",
    "MOLECLIP_CKPT = \"checkpoints/MoleCLIP - Primary.pth\"   # path to MoleCLIP checkpoint\n",
    "CLIP_MODEL_NAME = \"ViT-B/16\"                          # CLIP variant to match\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "FINETUNE_LAST_N = 3    # how many last transformer blocks to un-freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load CLIP ViT model (only image encoder used)\n",
    "#    Load on CPU first — we will move model to DEVICE after weight loading.\n",
    "clip_model, preprocess = clip.load(CLIP_MODEL_NAME, device=\"cpu\")\n",
    "class Backbone(nn.Module):\n",
    "    def __init__(self, clip_model):\n",
    "        super().__init__()\n",
    "        # Use only the image encoder (named \"visual\" in the CLIP wrapper)\n",
    "        self.visual = clip_model.visual\n",
    "    def forward(self, x):\n",
    "        return self.visual(x)\n",
    "\n",
    "backbone = Backbone(clip_model)  # currently on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_23192\\1644162022.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ck = torch.load(MOLECLIP_CKPT, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# 2) Load MoleCLIP checkpoint (on CPU) and inspect keys\n",
    "ck = torch.load(MOLECLIP_CKPT, map_location=\"cpu\")\n",
    "ck_model = ck[\"model\"] if isinstance(ck, dict) and \"model\" in ck else ck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-detected checkpoint prefix for visual weights: 'model_image.module.model.visual.'\n",
      "Checkpoint provides 152 keys under that prefix.\n",
      "backbone.visual expects 152 keys; 152 keys match by name under prefix.\n"
     ]
    }
   ],
   "source": [
    "# 3) Auto-detect best prefix that contains the image-encoder keys\n",
    "#    (we search for a prefix such that many keys start with it)\n",
    "possible_prefixes = [\n",
    "    \"model_image.module.model.visual.\",\n",
    "    \"model_image.model.visual.\",\n",
    "    \"model.visual.\", \"visual.\",\n",
    "    \"module.visual.\", \"backbone.visual.\",\n",
    "    \"clip.visual.\", \"visual\"\n",
    "]\n",
    "\n",
    "# fallback: also try to extract any prefix up to 'visual.' occurrence\n",
    "extra_prefixes = set()\n",
    "for k in ck_model.keys():\n",
    "    if \"visual.\" in k:\n",
    "        # take substring upto and including 'visual.'\n",
    "        idx = k.find(\"visual.\") + len(\"visual.\")\n",
    "        # find prefix that ends right before 'visual.' occurrence\n",
    "        prefix = k[:k.find(\"visual.\")+len(\"visual.\")]\n",
    "        extra_prefixes.add(prefix)\n",
    "possible_prefixes = list(possible_prefixes) + list(sorted(extra_prefixes))\n",
    "\n",
    "# function to count how many keys under a given prefix match backbone.visual keys\n",
    "backbone_sd = backbone.visual.state_dict()\n",
    "backbone_keys = set(backbone_sd.keys())\n",
    "\n",
    "best_prefix = None\n",
    "best_count = -1\n",
    "best_mapped = {}\n",
    "\n",
    "for prefix in possible_prefixes:\n",
    "    prefixed = {k: v for k, v in ck_model.items() if k.startswith(prefix)}\n",
    "    # mapped = stripped prefix names\n",
    "    mapped = {k[len(prefix):]: v for k, v in prefixed.items()}\n",
    "    common = set(mapped.keys()).intersection(backbone_keys)\n",
    "    if len(common) > best_count:\n",
    "        best_count = len(common)\n",
    "        best_prefix = prefix\n",
    "        best_mapped = mapped\n",
    "\n",
    "if best_prefix is None or best_count == 0:\n",
    "    raise RuntimeError(\"Could not find matching visual/encoder block in MoleCLIP checkpoint. \"\n",
    "                       \"Inspect checkpoint keys manually.\")\n",
    "\n",
    "print(f\"Auto-detected checkpoint prefix for visual weights: '{best_prefix}'\")\n",
    "print(f\"Checkpoint provides {len([k for k in ck_model.keys() if k.startswith(best_prefix)])} keys under that prefix.\")\n",
    "print(f\"backbone.visual expects {len(backbone_keys)} keys; {best_count} keys match by name under prefix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching tensors to load: 152\n",
      "Mismatched-shape tensors (will NOT be loaded): 0\n"
     ]
    }
   ],
   "source": [
    "# 4) Select only keys that both exist in backbone.visual and have matching shapes\n",
    "to_load = {}\n",
    "bad_shapes = []\n",
    "for k, v in best_mapped.items():\n",
    "    if k in backbone_sd:\n",
    "        if tuple(v.shape) == tuple(backbone_sd[k].shape):\n",
    "            to_load[k] = v\n",
    "        else:\n",
    "            bad_shapes.append((k, tuple(v.shape), tuple(backbone_sd[k].shape)))\n",
    "\n",
    "print(f\"Matching tensors to load: {len(to_load)}\")\n",
    "print(f\"Mismatched-shape tensors (will NOT be loaded): {len(bad_shapes)}\")\n",
    "if bad_shapes:\n",
    "    print(\"Some mismatches (first 20):\")\n",
    "    for i, item in enumerate(bad_shapes[:20]):\n",
    "        print(\" \", i, item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded MoleCLIP visual weights into backbone.visual (matching keys updated).\n"
     ]
    }
   ],
   "source": [
    "# 5) Load matching tensors into backbone.visual state dict (safe update)\n",
    "new_sd = backbone_sd.copy()\n",
    "new_sd.update(to_load)\n",
    "backbone.visual.load_state_dict(new_sd)   # we provide a filled state-dict (no unexpected keys)\n",
    "print(\"Loaded MoleCLIP visual weights into backbone.visual (matching keys updated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.visual device: cuda:0 dtype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# 6) Move backbone to DEVICE and inspect dtype/device\n",
    "backbone = backbone.to(DEVICE)\n",
    "first_param = next(backbone.visual.parameters())\n",
    "print(\"backbone.visual device:\", first_param.device, \"dtype:\", first_param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Instantiate VisCYPNet using this backbone\n",
    "from model_viscypnet import VisCYPNet\n",
    "model = VisCYPNet(\n",
    "    backbone=backbone,\n",
    "    head_hidden_dims=[256,64],\n",
    "    head_dropout=0.2,\n",
    "    device=DEVICE\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) By default freeze the entire backbone (common pattern when fine-tuning)\n",
    "for p in model.backbone.visual.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total transformer resblocks: 12; unfreezing last 3 blocks.\n"
     ]
    }
   ],
   "source": [
    "# 9) Un-freeze the last FINETUNE_LAST_N transformer blocks (if available)\n",
    "#    This accesses: model.backbone.visual.transformer.resblocks which is a nn.Sequential\n",
    "resblocks = model.backbone.visual.transformer.resblocks\n",
    "num_blocks = len(list(resblocks))\n",
    "N = min(FINETUNE_LAST_N, num_blocks)\n",
    "print(f\"Total transformer resblocks: {num_blocks}; unfreezing last {N} blocks.\")\n",
    "\n",
    "for block in list(resblocks)[-N:]:\n",
    "    for p in block.parameters():\n",
    "        p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameter tensors: 44\n",
      "  - backbone.visual.transformer.resblocks.9.attn.in_proj_weight\n",
      "  - backbone.visual.transformer.resblocks.9.attn.in_proj_bias\n",
      "  - backbone.visual.transformer.resblocks.9.attn.out_proj.weight\n",
      "  - backbone.visual.transformer.resblocks.9.attn.out_proj.bias\n",
      "  - backbone.visual.transformer.resblocks.9.ln_1.weight\n",
      "  - backbone.visual.transformer.resblocks.9.ln_1.bias\n",
      "  - backbone.visual.transformer.resblocks.9.mlp.c_fc.weight\n",
      "  - backbone.visual.transformer.resblocks.9.mlp.c_fc.bias\n",
      "  - backbone.visual.transformer.resblocks.9.mlp.c_proj.weight\n",
      "  - backbone.visual.transformer.resblocks.9.mlp.c_proj.bias\n",
      "  - backbone.visual.transformer.resblocks.9.ln_2.weight\n",
      "  - backbone.visual.transformer.resblocks.9.ln_2.bias\n",
      "  - backbone.visual.transformer.resblocks.10.attn.in_proj_weight\n",
      "  - backbone.visual.transformer.resblocks.10.attn.in_proj_bias\n",
      "  - backbone.visual.transformer.resblocks.10.attn.out_proj.weight\n",
      "  - backbone.visual.transformer.resblocks.10.attn.out_proj.bias\n",
      "  - backbone.visual.transformer.resblocks.10.ln_1.weight\n",
      "  - backbone.visual.transformer.resblocks.10.ln_1.bias\n",
      "  - backbone.visual.transformer.resblocks.10.mlp.c_fc.weight\n",
      "  - backbone.visual.transformer.resblocks.10.mlp.c_fc.bias\n",
      "  - backbone.visual.transformer.resblocks.10.mlp.c_proj.weight\n",
      "  - backbone.visual.transformer.resblocks.10.mlp.c_proj.bias\n",
      "  - backbone.visual.transformer.resblocks.10.ln_2.weight\n",
      "  - backbone.visual.transformer.resblocks.10.ln_2.bias\n",
      "  - backbone.visual.transformer.resblocks.11.attn.in_proj_weight\n",
      "  - backbone.visual.transformer.resblocks.11.attn.in_proj_bias\n",
      "  - backbone.visual.transformer.resblocks.11.attn.out_proj.weight\n",
      "  - backbone.visual.transformer.resblocks.11.attn.out_proj.bias\n",
      "  - backbone.visual.transformer.resblocks.11.ln_1.weight\n",
      "  - backbone.visual.transformer.resblocks.11.ln_1.bias\n",
      "  - backbone.visual.transformer.resblocks.11.mlp.c_fc.weight\n",
      "  - backbone.visual.transformer.resblocks.11.mlp.c_fc.bias\n",
      "  - backbone.visual.transformer.resblocks.11.mlp.c_proj.weight\n",
      "  - backbone.visual.transformer.resblocks.11.mlp.c_proj.bias\n",
      "  - backbone.visual.transformer.resblocks.11.ln_2.weight\n",
      "  - backbone.visual.transformer.resblocks.11.ln_2.bias\n",
      "  - head.mlp.0.weight\n",
      "  - head.mlp.0.bias\n",
      "  - head.mlp.1.weight\n",
      "  - head.mlp.1.bias\n"
     ]
    }
   ],
   "source": [
    "# 10) Check which parameters are trainable (sanity)\n",
    "trainable = [name for name, p in model.named_parameters() if p.requires_grad]\n",
    "print(f\"Number of trainable parameter tensors: {len(trainable)}\")\n",
    "# optional: print first few names for inspection\n",
    "for nm in trainable[:40]:\n",
    "    print(\"  -\", nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone trainable tensors: 36; head params approx: 8\n",
      "Optimizer created with 2 parameter groups (backbone small LR, head larger LR).\n"
     ]
    }
   ],
   "source": [
    "# 11) Build optimizer with two parameter groups:\n",
    "#     - backbone params (those that require grad) at a small LR\n",
    "#     - head params (usually model.head) at a larger LR\n",
    "backbone_params = [p for n, p in model.backbone.named_parameters() if p.requires_grad]\n",
    "# attempt to locate the head parameters robustly\n",
    "if hasattr(model, \"head\"):\n",
    "    head_params = [p for p in model.head.parameters()]\n",
    "else:\n",
    "    # fallback: treat any parameter not in backbone as 'head'\n",
    "    backbone_names = {n for n, p in model.backbone.named_parameters()}\n",
    "    head_params = [p for n, p in model.named_parameters() if n.split(\".\")[0] not in backbone_names]\n",
    "\n",
    "print(f\"Backbone trainable tensors: {len(backbone_params)}; head params approx: {len(head_params)}\")\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": backbone_params, \"lr\": 1e-6, \"weight_decay\": 1e-6},\n",
    "    {\"params\": head_params, \"lr\": 1e-4,     \"weight_decay\": 1e-4},\n",
    "])\n",
    "\n",
    "print(\"Optimizer created with 2 parameter groups (backbone small LR, head larger LR).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy forward OK. Visual output shape: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "# 12) Small verification: dummy forward (optional, but recommended)\n",
    "try:\n",
    "    dummy = torch.randn(1, 3, 224, 224, device=first_param.device, dtype=first_param.dtype)\n",
    "    with torch.no_grad():\n",
    "        out = model.backbone.visual(dummy)\n",
    "    print(\"Dummy forward OK. Visual output shape:\", getattr(out, \"shape\", None))\n",
    "except Exception as e:\n",
    "    print(\"Warning: dummy forward failed:\", e)\n",
    "    # If it fails, inspect dtype/device mismatch between dummy and model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisCYPNet(\n",
       "  (backbone): Backbone(\n",
       "    (visual): VisionTransformer(\n",
       "      (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)\n",
       "      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): Sequential(\n",
       "          (0): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): ResidualAttentionBlock(\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): QuickGELU()\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (head): CYPHead(\n",
       "    (mlp): Sequential(\n",
       "      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Dropout(p=0.2, inplace=False)\n",
       "      (4): Linear(in_features=256, out_features=64, bias=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Dropout(p=0.2, inplace=False)\n",
       "      (7): Linear(in_features=64, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Training Loop & Hyperparameter Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, random, os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from itertools import product\n",
    "\n",
    "# ensure you have \"preprocess\" from clip.load earlier in the notebook:\n",
    "# clip_model, preprocess = clip.load(\"ViT-B/16\", device=\"cpu\")  # done earlier\n",
    "\n",
    "# Use CPU/GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== Loader factory (use CLIP preprocess as transform) =====\n",
    "from ImageDataset import CYPImageDataset\n",
    "\n",
    "def make_loaders(batch_size):\n",
    "    # pass CLIP preprocess (returns tensor normalized for the backbone)\n",
    "    train_ds = CYPImageDataset(\n",
    "        csv_file=\"../data/processed/1A2_train.csv\",\n",
    "        image_dir=\"../images/1A2/train/clean\",\n",
    "        transform=preprocess\n",
    "    )\n",
    "    val_ds = CYPImageDataset(\n",
    "        csv_file=\"../data/processed/1A2_val.csv\",\n",
    "        image_dir=\"../images/1A2/val/clean\",\n",
    "        transform=preprocess\n",
    "    )\n",
    "    test_ds = CYPImageDataset(\n",
    "        csv_file=\"../data/processed/1A2_test.csv\",\n",
    "        image_dir=\"../images/1A2/test/clean\",\n",
    "        transform=preprocess\n",
    "    )\n",
    "\n",
    "    # num_workers tuned to your machine; pin_memory True if using CUDA\n",
    "    pin = True if device.type == \"cuda\" else False\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=4, pin_memory=pin)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=2, pin_memory=pin)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=2, pin_memory=pin)\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:3: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ===== Training helpers (handle label shapes & optional AMP) =====\n",
    "use_amp = True if device.type == \"cuda\" else False\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, device, amp=scaler):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    n = 0\n",
    "    for imgs, lbls in loader:\n",
    "        # imgs expected as tensor (C,H,W) after preprocess\n",
    "        imgs = imgs.to(device, non_blocking=True)\n",
    "        # ensure labels are float and same shape as logits later\n",
    "        lbls = lbls.float().to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(imgs)                              # logits shape (B,1) or (B,)\n",
    "                # If logits are (B,1), make labels (B,1)\n",
    "                if logits.dim() == 2 and logits.shape[1] == 1:\n",
    "                    lbl = lbls.view(-1,1)\n",
    "                else:\n",
    "                    lbl = lbls.view(-1)\n",
    "                loss = loss_fn(logits, lbl)\n",
    "            amp.scale(loss).backward()\n",
    "            amp.step(optimizer)\n",
    "            amp.update()\n",
    "        else:\n",
    "            logits = model(imgs)\n",
    "            if logits.dim() == 2 and logits.shape[1] == 1:\n",
    "                lbl = lbls.view(-1,1)\n",
    "            else:\n",
    "                lbl = lbls.view(-1)\n",
    "            loss = loss_fn(logits, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        n += imgs.size(0)\n",
    "    return total_loss / max(1, n)\n",
    "\n",
    "def compute_auc(model, loader, device):\n",
    "    model.eval()\n",
    "    all_probs, all_lbls = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device, non_blocking=True)\n",
    "            lbls = lbls.cpu().numpy().flatten()\n",
    "            # forward: handle mixed precision if enabled\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(imgs)\n",
    "            else:\n",
    "                logits = model(imgs)\n",
    "            probs = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "            all_probs.extend(probs.tolist())\n",
    "            all_lbls.extend(lbls.tolist())\n",
    "    try:\n",
    "        return roc_auc_score(all_lbls, all_probs)\n",
    "    except Exception:\n",
    "        return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Hyperparameter search setup  =====\n",
    "search_space = {\n",
    "    'head_lr':     [1e-3, 1e-4, 1e-5],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'dropout':    [0.0, 0.2, 0.5],\n",
    "    'weight_decay':[1e-4, 1e-3, 1e-2],\n",
    "}\n",
    "param_grid = list(product(\n",
    "    search_space['head_lr'],\n",
    "    search_space['batch_size'],\n",
    "    search_space['dropout'],\n",
    "    search_space['weight_decay'],\n",
    "))\n",
    "random.shuffle(param_grid)\n",
    "max_trials = min(10, len(param_grid))\n",
    "\n",
    "# fix seeds\n",
    "random.seed(42); np.random.seed(42); torch.manual_seed(42)\n",
    "if device.type == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "best_auc    = 0.0\n",
    "best_params = None\n",
    "best_state  = None   # store state_dict of best model to save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trial 1/10: lr=0.0001, bs=16, dropout=0.2, wd=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.4729, val_auc=0.9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.3843, val_auc=0.9116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.3440, val_auc=0.9200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.3086, val_auc=0.9198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.2717, val_auc=0.9185\n",
      "\n",
      "Trial 2/10: lr=0.001, bs=32, dropout=0.2, wd=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.3314, val_auc=0.9209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.2665, val_auc=0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.2267, val_auc=0.9119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.1926, val_auc=0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.1527, val_auc=0.9039\n",
      "\n",
      "Trial 3/10: lr=0.0001, bs=16, dropout=0.0, wd=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.3293, val_auc=0.9227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.2031, val_auc=0.9234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.1545, val_auc=0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.1223, val_auc=0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.0948, val_auc=0.9145\n",
      "\n",
      "Trial 4/10: lr=1e-05, bs=32, dropout=0.2, wd=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.5831, val_auc=0.8951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.4003, val_auc=0.9190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.3157, val_auc=0.9284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.2588, val_auc=0.9314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.2148, val_auc=0.9313\n",
      "\n",
      "Trial 5/10: lr=0.001, bs=32, dropout=0.5, wd=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.1819, val_auc=0.9205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.1171, val_auc=0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.0868, val_auc=0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.0745, val_auc=0.9108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.0638, val_auc=0.9076\n",
      "\n",
      "Trial 6/10: lr=0.001, bs=64, dropout=0.5, wd=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.1267, val_auc=0.9182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.0555, val_auc=0.9128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.0426, val_auc=0.9042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.0383, val_auc=0.9022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.0338, val_auc=0.9053\n",
      "\n",
      "Trial 7/10: lr=1e-05, bs=64, dropout=0.5, wd=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.6085, val_auc=0.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.4512, val_auc=0.9238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.3543, val_auc=0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.2933, val_auc=0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.2425, val_auc=0.9346\n",
      "\n",
      "Trial 8/10: lr=0.0001, bs=64, dropout=0.2, wd=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.2466, val_auc=0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.0850, val_auc=0.9259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.0498, val_auc=0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.0339, val_auc=0.9222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.0252, val_auc=0.9170\n",
      "\n",
      "Trial 9/10: lr=0.0001, bs=16, dropout=0.2, wd=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.1148, val_auc=0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.0303, val_auc=0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.0217, val_auc=0.9125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.0173, val_auc=0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.0166, val_auc=0.9054\n",
      "\n",
      "Trial 10/10: lr=1e-05, bs=16, dropout=0.2, wd=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: train_loss=0.3670, val_auc=0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 2: train_loss=0.1203, val_auc=0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 3: train_loss=0.0539, val_auc=0.9315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 4: train_loss=0.0279, val_auc=0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:17: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\3201937847.py:51: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 5: train_loss=0.0188, val_auc=0.9293\n",
      "Saved best model -> best_viscypnet_moleclip.pth with params: {'lr': 1e-05, 'bs': 64, 'dropout': 0.5, 'wd': 0.001} AUC: 0.934586302424399\n"
     ]
    }
   ],
   "source": [
    "# ===== Run Random Search =====\n",
    "from model_viscypnet import VisCYPNet\n",
    "\n",
    "for i, (lr, bs, do, wd) in enumerate(param_grid[:max_trials], 1):\n",
    "    print(f\"\\nTrial {i}/{max_trials}: lr={lr}, bs={bs}, dropout={do}, wd={wd}\")\n",
    "\n",
    "    # loaders\n",
    "    train_loader, val_loader, test_loader = make_loaders(bs)\n",
    "\n",
    "    # instantiate fresh model; ensure backbone is used (backbone already loaded earlier)\n",
    "    model = VisCYPNet(\n",
    "        backbone=backbone,               # MoleCLIP backbone loaded earlier\n",
    "        head_hidden_dims=[256,64],\n",
    "        head_dropout=do,\n",
    "        device=device\n",
    "    ).to(device)\n",
    "\n",
    "    # Force model dtype to match backbone's first param dtype (avoid float16/float32 mismatch)\n",
    "    first_param = next(model.backbone.visual.parameters())\n",
    "    model = model.to(device=device, dtype=first_param.dtype)\n",
    "\n",
    "    # Freeze backbone then unfreeze last N blocks\n",
    "    for p in model.backbone.visual.parameters():\n",
    "        p.requires_grad = False\n",
    "\n",
    "    N = 3\n",
    "    resblocks = model.backbone.visual.transformer.resblocks\n",
    "    for block in list(resblocks)[-N:]:\n",
    "        for p in block.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "    # Build optimizer (must collect parameters after updating requires_grad)\n",
    "    backbone_params = [p for p in model.backbone.parameters() if p.requires_grad]\n",
    "    head_params = [p for p in model.head.parameters()]\n",
    "\n",
    "    optimizer = torch.optim.AdamW([\n",
    "        {'params': backbone_params, 'lr': 5e-7, 'weight_decay': 1e-6},\n",
    "        {'params': head_params,     'lr': lr,   'weight_decay': wd}\n",
    "    ])\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # quick training (5 epochs)\n",
    "    for epoch in range(1, 6):\n",
    "        tr_loss = train_one_epoch(model, train_loader, optimizer, loss_fn, device)\n",
    "        val_auc = compute_auc(model, val_loader, device)\n",
    "        print(f\"  Epoch {epoch}: train_loss={tr_loss:.4f}, val_auc={val_auc:.4f}\")\n",
    "\n",
    "    # Track best: save state_dict (less memory than deepcopy)\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        best_params = {'lr': lr, 'bs': bs, 'dropout': do, 'wd': wd}\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}  # keep on CPU\n",
    "\n",
    "# After search, save best model weights\n",
    "if best_state is not None:\n",
    "    torch.save(best_state, \"best_viscypnet_moleclip.pth\")\n",
    "    print(\"Saved best model -> best_viscypnet_moleclip.pth with params:\", best_params, \"AUC:\", best_auc)\n",
    "else:\n",
    "    print(\"No model improved on initial best_auc.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 & Step 7: Final Training, Validation Check & Test Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We rebuild the loaders using the chosen best_bs.\n",
    "\n",
    "We train for 20 epochs, tracking validation ROC AUC and saving the best model state.\n",
    "\n",
    "After training, we save the best weights to models/Without_Augmentation_CYP1A2.pth.\n",
    "\n",
    "We define compute_metrics to calculate ROC AUC, BA, MCC, PRE, REC, and F1 at a 0.5 threshold.\n",
    "\n",
    "Finally, we load the best weights back into model and print all metrics for train, val, and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, copy\n",
    "import torch, numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import (balanced_accuracy_score, matthews_corrcoef,\n",
    "                             precision_score, recall_score, f1_score, roc_auc_score)\n",
    "from ImageDataset import CYPImageDataset\n",
    "from model_viscypnet import VisCYPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 1) Best hyperparameters (from Step 5)\n",
    "# -------------------------\n",
    "#  {'lr': 1e-05, 'bs': 64, 'dropout': 0.5, 'wd': 0.001}\n",
    "best_lr = 1e-05\n",
    "best_bs = 64\n",
    "best_do = 0.5\n",
    "best_wd = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 2) Transform & DataLoaders\n",
    "# -------------------------\n",
    "# prefer the CLIP 'preprocess' used earlier; if not available fall back to no_aug_transforms\n",
    "try:\n",
    "    preprocess  # noqa: F821\n",
    "    transform_for_dataset = preprocess\n",
    "except NameError:\n",
    "    # fallback: define minimal no-aug transforms (assumes torchvision.transforms imported earlier)\n",
    "    import torchvision.transforms as transforms\n",
    "    CLIP_MEAN = (0.48145466, 0.4578275, 0.40821073)\n",
    "    CLIP_STD  = (0.26862954, 0.26130258, 0.27577711)\n",
    "    no_aug_transforms = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(CLIP_MEAN, CLIP_STD)\n",
    "    ])\n",
    "    transform_for_dataset = no_aug_transforms\n",
    "\n",
    "def make_loaders(batch_size):\n",
    "    ds_train = CYPImageDataset(csv_file=\"../data/processed/1A2_train.csv\",\n",
    "                               image_dir=\"../images/1A2/train/clean\",\n",
    "                               transform=transform_for_dataset)\n",
    "    ds_val   = CYPImageDataset(csv_file=\"../data/processed/1A2_val.csv\",\n",
    "                               image_dir=\"../images/1A2/val/clean\",\n",
    "                               transform=transform_for_dataset)\n",
    "    ds_test  = CYPImageDataset(csv_file=\"../data/processed/1A2_test.csv\",\n",
    "                               image_dir=\"../images/1A2/test/clean\",\n",
    "                               transform=transform_for_dataset)\n",
    "    pin = True if torch.cuda.is_available() else False\n",
    "    train_loader = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=pin)\n",
    "    val_loader   = DataLoader(ds_val,   batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=pin)\n",
    "    test_loader  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=pin)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "train_loader, val_loader, test_loader = make_loaders(best_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 3) Instantiate model & align device + dtype with backbone\n",
    "# -------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# IMPORTANT: 'backbone' should already be loaded with MoleCLIP visual weights\n",
    "# (from your earlier cell). We'll use the dtype/device of backbone.visual's first param.\n",
    "first_backbone_param = next(backbone.visual.parameters())\n",
    "backbone_device = first_backbone_param.device\n",
    "backbone_dtype  = first_backbone_param.dtype\n",
    "\n",
    "model = VisCYPNet(backbone=backbone, head_hidden_dims=[256,64], head_dropout=best_do, device=device)\n",
    "\n",
    "# Move entire model to device and to the same dtype as backbone visual params to prevent mismatch\n",
    "model = model.to(device=backbone_device, dtype=backbone_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 4) Freeze backbone and unfreeze last N transformer blocks, BEFORE building optimizer\n",
    "# -------------------------\n",
    "# Freeze all backbone visual params\n",
    "for p in model.backbone.visual.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# Un-freeze last N transformer blocks\n",
    "N = 3\n",
    "resblocks = model.backbone.visual.transformer.resblocks\n",
    "num_blocks = len(list(resblocks))\n",
    "N = min(N, num_blocks)\n",
    "for block in list(resblocks)[-N:]:\n",
    "    for p in block.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# Also make sure the head parameters require grad\n",
    "for p in model.head.parameters():\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------\n",
    "# 5) Build optimizer with two parameter groups (after requires_grad set)\n",
    "# -------------------------\n",
    "backbone_trainable_params = [p for p in model.backbone.parameters() if p.requires_grad]\n",
    "head_params = [p for p in model.head.parameters() if p.requires_grad]\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {\"params\": backbone_trainable_params, \"lr\": 5e-7, \"weight_decay\": 1e-6},\n",
    "    {\"params\": head_params,               \"lr\": best_lr, \"weight_decay\": best_wd}\n",
    "])\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.5694 | Val ROC AUC: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 0.3525 | Val ROC AUC: 0.9373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 0.2243 | Val ROC AUC: 0.9377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 0.1447 | Val ROC AUC: 0.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 0.0936 | Val ROC AUC: 0.9343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 0.0644 | Val ROC AUC: 0.9336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | Train Loss: 0.0442 | Val ROC AUC: 0.9323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | Train Loss: 0.0341 | Val ROC AUC: 0.9322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | Train Loss: 0.0260 | Val ROC AUC: 0.9324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:23: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\4250615879.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.0213 | Val ROC AUC: 0.9317\n",
      "Saved best model state_dict (Val AUC=0.9377) -> models/VisCYPNet_CYP1A2.pth\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 6) Train with AMP if CUDA (safe dtype handling)\n",
    "# -------------------------\n",
    "use_amp = True if (torch.cuda.is_available()) else False\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "num_epochs = 10\n",
    "best_val_auc = -1.0\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    n_samples = 0\n",
    "    for imgs, lbls in train_loader:\n",
    "        # imgs should already be tensors (preprocess) with correct normalization; move to backbone device/dtype\n",
    "        imgs = imgs.to(device=backbone_device, dtype=backbone_dtype, non_blocking=True)\n",
    "        lbls = lbls.float().to(device=backbone_device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if use_amp:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(imgs)  # shape: (B,1) or (B,)\n",
    "                if logits.dim()==2 and logits.shape[1]==1:\n",
    "                    lbl = lbls.view(-1,1)\n",
    "                else:\n",
    "                    lbl = lbls.view(-1)\n",
    "                loss = loss_fn(logits, lbl)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(imgs)\n",
    "            if logits.dim()==2 and logits.shape[1]==1:\n",
    "                lbl = lbls.view(-1,1)\n",
    "            else:\n",
    "                lbl = lbls.view(-1)\n",
    "            loss = loss_fn(logits, lbl)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        n_samples += imgs.size(0)\n",
    "\n",
    "    train_loss = running_loss / max(1, n_samples)\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    all_logits = []\n",
    "    all_lbls = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in val_loader:\n",
    "            imgs = imgs.to(device=backbone_device, dtype=backbone_dtype, non_blocking=True)\n",
    "            lbls_np = lbls.numpy().flatten()\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(imgs)\n",
    "            else:\n",
    "                logits = model(imgs)\n",
    "\n",
    "            logits_np = logits.detach().cpu().numpy().flatten()\n",
    "            all_logits.extend(logits_np.tolist())\n",
    "            all_lbls.extend(lbls_np.tolist())\n",
    "\n",
    "    probs = 1.0 / (1.0 + np.exp(-np.array(all_logits)))\n",
    "    try:\n",
    "        val_auc = roc_auc_score(all_lbls, probs)\n",
    "    except Exception:\n",
    "        val_auc = 0.5\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | Train Loss: {train_loss:.4f} | Val ROC AUC: {val_auc:.4f}\")\n",
    "\n",
    "    # Checkpoint best model (save state_dict to CPU)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        # copy state_dict to CPU tensors to avoid GPU memory pinning\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "# Save best model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "path = \"models/VisCYPNet_CYP1A2.pth\"\n",
    "if best_state is not None:\n",
    "    torch.save(best_state, path)\n",
    "    print(f\"Saved best model state_dict (Val AUC={best_val_auc:.4f}) -> {path}\")\n",
    "else:\n",
    "    print(\"No model improved during training; nothing saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Metrics ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\1498260162.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ROC_AUC=0.9977, BA=0.9841, MCC=0.9674, PRE=0.9772, REC=0.9873, F1=0.9822, ACC=0.9838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\1498260162.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val: ROC_AUC=0.9377, BA=0.8509, MCC=0.7027, PRE=0.8414, REC=0.8717, F1=0.8563, ACC=0.8512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Afra\\AppData\\Local\\Temp\\ipykernel_5288\\1498260162.py:16: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: ROC_AUC=0.9378, BA=0.8689, MCC=0.7380, PRE=0.8748, REC=0.8594, F1=0.8670, ACC=0.8689\n"
     ]
    }
   ],
   "source": [
    "# -------------------------\n",
    "# 7) Load best_state and evaluate on Train/Val/Test with final metrics\n",
    "# -------------------------\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)   # ensure model has best weights\n",
    "model = model.to(device=backbone_device, dtype=backbone_dtype)\n",
    "model.eval()\n",
    "\n",
    "def compute_metrics(model, loader, device_dtype):\n",
    "    model.eval()\n",
    "    logits_list, labels_list = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, lbls in loader:\n",
    "            imgs = imgs.to(device=backbone_device, dtype=backbone_dtype, non_blocking=True)\n",
    "            if use_amp:\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    logits = model(imgs).detach().cpu().numpy().flatten()\n",
    "            else:\n",
    "                logits = model(imgs).detach().cpu().numpy().flatten()\n",
    "            logits_list.extend(logits.tolist())\n",
    "            labels_list.extend(lbls.numpy().flatten().tolist())\n",
    "\n",
    "    probs = 1.0 / (1.0 + np.exp(-np.array(logits_list)))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "    # metrics (safe wrt single-class / degenerate cases)\n",
    "    metrics = {}\n",
    "    try:\n",
    "        metrics[\"ROC_AUC\"] = roc_auc_score(labels_list, probs)\n",
    "    except Exception:\n",
    "        metrics[\"ROC_AUC\"] = float(\"nan\")\n",
    "    try:\n",
    "        metrics[\"BA\"] = balanced_accuracy_score(labels_list, preds)\n",
    "    except Exception:\n",
    "        metrics[\"BA\"] = float(\"nan\")\n",
    "    try:\n",
    "        metrics[\"MCC\"] = matthews_corrcoef(labels_list, preds)\n",
    "    except Exception:\n",
    "        metrics[\"MCC\"] = float(\"nan\")\n",
    "    metrics[\"PRE\"] = precision_score(labels_list, preds, zero_division=0)\n",
    "    metrics[\"REC\"] = recall_score(labels_list, preds, zero_division=0)\n",
    "    metrics[\"F1\"]  = f1_score(labels_list, preds, zero_division=0)\n",
    "    metrics[\"ACC\"] = np.mean(preds == np.array(labels_list))\n",
    "    return metrics\n",
    "\n",
    "print(\"\\n=== Final Metrics ===\")\n",
    "for split, loader in [(\"Train\", train_loader), (\"Val\", val_loader), (\"Test\", test_loader)]:\n",
    "    m = compute_metrics(model, loader, backbone_dtype)\n",
    "    line = \", \".join(f\"{k}={v:.4f}\" if isinstance(v, (float, np.floating)) else f\"{k}={v}\" for k,v in m.items())\n",
    "    print(f\"{split}: {line}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
